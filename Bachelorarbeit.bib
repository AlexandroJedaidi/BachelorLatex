
@article{aristoffIMPLICITRUNGEKUTTAMETHODS,
  title = {{{IMPLICIT RUNGE-KUTTA METHODS FOR UNCERTAINTY PROPAGATION}}},
  author = {Aristoff, Jeffrey M and Horwood, Joshua T and Poore, Aubrey B},
  pages = {8},
  abstract = {Accurate and efficient orbital propagators are critical for space situational awareness because they drive uncertainty propagation which is necessary for tracking, conjunction analysis, and maneuver detection. Existing sigma point- or particle-based methods for uncertainty propagation use explicit numerical integrators for propagating the closely spaced orbital states as part of the prediction step of the nonlinear filter (e.g. the unscented Kalman filter, Gaussian sum filter, or particle filter). As such, these methods cannot exploit the proximity of the orbital states, and each orbit is propagated independently. To remove this limitation and enable the orbital states to be propagated together, we have developed an implicit Runge-Kutta-based method for uncertainty propagation, and consider the propagation of the 13 sigma points needed to represent uncertainty (of a six-dimensional Gaussian state) in the unscented Kalman filter. In some cases, we can propagate uncertainty using the new propagator at about the same computational cost compared to that of propagating a single orbital state, even before the algorithm is potentially parallelized. The new propagator is applicable to all regimes of space, and additional features include its ability to estimate and control the truncation error, exploit analytic and semi-analytic methods, and provide accurate ephemeris data via built-in interpolation.},
  langid = {english},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\H62CZZWD\\Aristoﬀ et al. - IMPLICIT RUNGE-KUTTA METHODS FOR UNCERTAINTY PROPA.pdf}
}

@book{aulbachGewohnlicheDifferentialgleichungen2004,
  title = {Gewöhnliche {{Differentialgleichungen}}},
  author = {Aulbach, Bernd},
  date = {2004},
  publisher = {{Spektrum Akademischer Verlag}},
  location = {{Heidelberg}}
}

@misc{beckGewohnlicheDifferentialgleichungen2016,
  title = {Gewöhnliche Differentialgleichungen},
  author = {Beck, Lisa},
  year = {Wintersemester 2016/17},
  publisher = {{Universität Augsburg}},
  langid = {german}
}

@inproceedings{bengioCurriculumLearning2009,
  title = {Curriculum Learning},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}} - {{ICML}} '09},
  author = {Bengio, Yoshua and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
  date = {2009},
  pages = {1--8},
  publisher = {{ACM Press}},
  location = {{Montreal, Quebec, Canada}},
  doi = {10.1145/1553374.1553380},
  url = {http://portal.acm.org/citation.cfm?doid=1553374.1553380},
  urldate = {2022-02-19},
  abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them “curriculum learning”. In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
  eventtitle = {The 26th {{Annual International Conference}}},
  isbn = {978-1-60558-516-1},
  langid = {english},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\F2WXM8ER\\Bengio et al. - 2009 - Curriculum learning.pdf}
}

@online{BeweisarchivAnalysisUngleichungen,
  title = {Beweisarchiv: Analysis: Ungleichungen: Grönwall'sche Ungleichung – Wikibooks, Sammlung freier Lehr-, Sach- und Fachbücher},
  shorttitle = {Beweisarchiv},
  url = {https://de.wikibooks.org/wiki/Beweisarchiv:_Analysis:_Ungleichungen:_Gr%C3%B6nwall%27sche_Ungleichung},
  urldate = {2022-01-13},
  langid = {german},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\7S9CYJSF\\Beweisarchiv_Analysis_Ungleichungen_Grönwall'sche_Ungleichung.html}
}

@book{calinDeepLearningArchitectures2020,
  title = {Deep Learning Architectures: A Mathematical Approach},
  author = {Calin, Ovidiu},
  date = {2020-02-14},
  publisher = {{Springer}},
  isbn = {978-3-030-36720-6},
  langid = {Englisch}
}

@book{deuflhardNumerischeMathematik2018,
  title = {Numerische Mathematik 1},
  author = {Deuflhard, Peter and Hohmann, Andreas},
  date = {2018-12-17},
  edition = {5. Auflage},
  publisher = {{De Gruyter}},
  langid = {german}
}

@book{deuflhardNumerischeMathematikGewohnliche2013,
  title = {Numerische {{Mathematik}} 2 {{Gewöhnliche Differentialgleichungen}}},
  author = {Deuflhard, Peter and Bornemann, Folkmar},
  date = {2013-08-19},
  edition = {3. Auflage},
  publisher = {{Walter de Gruyter}},
  location = {{Berlin, New York}}
}

@misc{flamantPersonlicheKommunikation2022,
  title = {Persönliche Kommunikation},
  date = {2022-03-24},
  editora = {Flamant, Cedric},
  editoratype = {collaborator},
  langid = {Englisch}
}

@unpublished{flamantSolvingDifferentialEquations2020,
  title = {Solving {{Differential Equations Using Neural Network Solution Bundles}}},
  author = {Flamant, Cedric and Protopapas, Pavlos and Sondak, David},
  date = {2020-06-16},
  eprint = {2006.14372},
  eprinttype = {arxiv},
  primaryclass = {physics},
  url = {http://arxiv.org/abs/2006.14372},
  urldate = {2022-02-15},
  abstract = {The time evolution of dynamical systems is frequently described by ordinary differential equations (ODEs), which must be solved for given initial conditions. Most standard approaches numerically integrate ODEs producing a single solution whose values are computed at discrete times. When many varied solutions with different initial conditions to the ODE are required, the computational cost can become significant. We propose that a neural network be used as a solution bundle, a collection of solutions to an ODE for various initial states and system parameters. The neural network solution bundle is trained with an unsupervised loss that does not require any prior knowledge of the sought solutions, and the resulting object is differentiable in initial conditions and system parameters. The solution bundle exhibits fast, parallelizable evaluation of the system state, facilitating the use of Bayesian inference for parameter estimation in real dynamical systems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Physics - Computational Physics},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\38896GZ6\\Flamant et al. - 2020 - Solving Differential Equations Using Neural Networ.pdf}
}

@book{hairerSolvingOrdinaryDifferential,
  title = {Solving {{Ordinary Differential Equations I Nonstiff Problems}}},
  author = {Hairer, Ernst and Wanner, Gerhard},
  publisher = {{Springer}},
  location = {{NTNU, 7491 Trondheim, Norwegen}}
}

@book{hairerSolvingOrdinaryDifferentiala,
  title = {Solving {{Ordinary Differential Equations II}}: {{Stiff}} and {{Differential-Algebraic Problems}}},
  author = {Hairer, Ernst and Wanner, Gerhard},
  edition = {2. Auflage},
  publisher = {{Springer}},
  location = {{NTNU, 7491 Trondheim, Norwegen}}
}

@book{heuserGewohnlicheDifferentialgleichungen2009,
  title = {Gewöhnliche {{Differentialgleichungen}}},
  author = {Heuser, Harro},
  date = {2009},
  edition = {6. Auflage},
  publisher = {{Vieweg+Teubner Verlag}},
  isbn = {978-3-8348-0705-2}
}

@online{LipschitzStetigkeitSerloMathe,
  title = {Lipschitz-Stetigkeit – Serlo „Mathe für Nicht-Freaks“ – Wikibooks, Sammlung freier Lehr-, Sach- und Fachbücher},
  url = {https://de.wikibooks.org/wiki/Mathe_f%C3%BCr_Nicht-Freaks:_Lipschitz-Stetigkeit},
  urldate = {2022-01-13},
  langid = {german},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\KN6MCIWN\\Mathe_für_Nicht-Freaks_Lipschitz-Stetigkeit.html}
}

@online{Matrixexponential,
  title = {Matrixexponential},
  url = {https://www.biancahoegel.de/mathe/analysis/matrixexponential.html},
  urldate = {2022-02-17},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\N5GQJCNZ\\matrixexponential.html}
}

@book{NumerischeMathematikAlgorithmisch2008,
  title = {Numerische Mathematik. 1: Eine algorithmisch orientierte Einführung},
  shorttitle = {Numerische Mathematik. 1},
  date = {2008},
  series = {de Gruyter Lehrbuch},
  edition = {4., überarb. und erw. Aufl},
  publisher = {{de Gruyter}},
  location = {{Berlin}},
  isbn = {978-3-11-020354-7},
  langid = {german},
  pagetotal = {375},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\VN3JQTLR\\2008 - Numerische Mathematik. 1 Eine algorithmisch orien.pdf}
}

@online{PandasDataFrameMean,
  title = {Pandas.{{DataFrame}}.Mean — Pandas 1.4.2 Documentation},
  url = {https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html},
  urldate = {2022-04-07},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\EXIEZJKW\\pandas.DataFrame.mean.html}
}

@misc{remcovandermeerSolvingPartialDifferential2019,
  title = {Solving Partial Differential Equations with Neural Networks},
  author = {{Remco van der Meer}},
  date = {2019-06},
  abstract = {Recent works have shown that neural networks can be employed to solve partial differential equations, bringing rise to the framework of physics informed neural networks.The aim of this project is to gain a deeper understanding of these novel methods, and to use these insights to further improve them. We show that solving a partial differential equation can be formulated as a multi-objective optimization problem, and use this formulation to propose several modifications to existing methods. These modifications manifest as a scaling parameter, which can improve the accuracy by orders of magnitude for certain problems when it is chosen properly. We also propose heuristic methods to approximate the optimal scaling parameter, which can be used to eliminate the need to optimize this parameter. Our proposed methods are tested on a variety of partial differential equations and compared to existing methods. These partial differential equations include the Laplace equation, which we solve in up to four dimensions, the convection-diffucsion equation and the Helmholtz equation, all of which show that our proposed odifications lead to enhanced accuracy.},
  langid = {Englisch},
  file = {C\:\\Users\\as-al\\Downloads\\ba\\Quellen\\Thesis.pdf}
}

@online{SamplingMethods,
  title = {Sampling Methods},
  url = {https://ermongroup.github.io/cs228-notes/inference/sampling/},
  urldate = {2022-02-20},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\9ADU7IEX\\sampling.html}
}

@online{ScipyIntegrateBDF,
  title = {Scipy.Integrate.{{BDF}} — {{SciPy}} v1.8.0 {{Manual}}},
  url = {https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.BDF.html},
  urldate = {2022-04-01},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\TVLXEVUT\\scipy.integrate.BDF.html}
}

@online{ScipyIntegrateRK45,
  title = {Scipy.Integrate.{{RK45}} — {{SciPy}} v1.8.0 {{Manual}}},
  url = {https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.RK45.html},
  urldate = {2022-04-01},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\ZUNBFUB2\\scipy.integrate.RK45.html}
}

@book{stoerNumerischeMathematik2005,
  title = {Numerische Mathematik 2},
  author = {Stoer, Prof. Dr. Josef and Bulirsch, Prof. Dr. Roland},
  date = {2005},
  edition = {5. Auflage},
  publisher = {{Springer}},
  location = {{Würzburg, Garching}},
  isbn = {3-540-23777-1},
  langid = {german}
}

@misc{stykelSkriptZurVorlesung2020,
  title = {Skript zur Vorlesung Numerik Gewöhnlicher Differentialgleichungen},
  author = {Stykel, Tatjana},
  year = {Sommersemester 2020},
  langid = {german}
}

@online{sundermeierFixpunktsatzSchauder,
  title = {Der Fixpunktsatz von Schauder},
  author = {Sundermeier, Jan Frederik},
  url = {https://www.math.uni-bielefeld.de/~emmrich/studenten/ba-freddy.pdf},
  urldate = {2022-01-21},
  langid = {german},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\YNUNLQNX\\Sundermeier - Der Fixpunktsatz von Schauder.pdf}
}

@book{walzLexikonMathematik2017,
  title = {Lexikon der Mathematik},
  author = {Walz, Guido},
  date = {2017},
  edition = {1.},
  volume = {1},
  publisher = {{Springer Spektrum Akademischer Verlag}},
  isbn = {3-8274-0439-8},
  langid = {german}
}

@online{wangVanishingGradientProblem2019,
  title = {The {{Vanishing Gradient Problem}}},
  author = {Wang, Chi-Feng},
  date = {2019-01-08T13:59:01},
  url = {https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484},
  urldate = {2022-02-19},
  abstract = {The Problem, Its Causes, Its Significance, and Its Solutions},
  langid = {english},
  organization = {{Medium}},
  file = {C\:\\Users\\as-al\\Zotero\\storage\\P93L56ZG\\the-vanishing-gradient-problem-69bf08b15484.html}
}


