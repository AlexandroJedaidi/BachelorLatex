\section{neuronale Netze}
In diesem Abschnitt werden wir eine weitere Möglichkeit betrachen, ein Anfangswertproblem zu lösen.
Dabei gehen wir genauer auf neuronale Netze ein. Dieser Abschnitt bezieht sich hauptsächlich auf
\cite{ovidiucalinDeepLearningArchitectures} und auch Grundlagen zu neuronalen Netzen wie Beispielsweise
\textit{Forward}- und \textit{Backwardpropagation} lassen sich in \cite[Chapter 6]{ovidiucalinDeepLearningArchitectures}
nachlesen. Obwohl die bisher besprochenen numerischen Verfahen wie Runge-Kutta- und Mehrschrittverfahren heutzutage
extrem effizient in Bezug auf Fehlertoleranz und Rechenaufwand sind, gibt es dennoch Vorteile neuronale Netze zu
benutzen. Falls Beispielsweise die Interesse besteht, die Lösung einer gewöhnlichen Differentialgleichung nur in einem
bestimmten Zeitpunkt $\hat{t}$ auszuwerten, so müssen in numerischen Verfahren von der Anfangszeit $t_0$ bis zur
gewünschten Zeit $\hat{t}$ iteriert werden. Ein \textit{trainiertes} neuronales Netz repräsentiert jedoch die gesuchte
Lösung und ist deshalb in der Lage eine Funktionsauswertung in $\hat{t}$ auszuführen, was im Gegensatz zu den
numerischen Verfahren viel Rechenarbeit spart. Neuronale Netze haben in unserem Anwendungsgebiet noch einen
ausschlaggebenden Vorteil in Bezug auf Recheneffizienz, welchen wir in Abschnitt \ref{subsec:lsgpakete} betrachten
werden.

\subsection{Struktur neuronaler Netze}
\label{subsec:struktur-eines-neuronalen-netzes}
Zuerst werden wir die grundlegenden Begrifflichkeiten eines neuronalen Netzes definieren. Zur Übersicht beschränken
wir uns auf ein neuronales Netz mit einer Eingangsschicht mit $3$ Neuronen, zwei versteckte Schichten mit jeweils
3 Neuronen und eine Ausgangsschicht mit 2 Neuronen wie in \eqref{neuralNetexample} dargestellt. Die gelben Neuronen
repräsentieren hier jeweils ein \textit{on-Neuron}, oder \textit{bias}, welches konstant $x_0^{(l)} = -1$ ist. Allgemein
haben wir $L$ Schichten und $n^{(l)}$, $1\leq l \leq L$, Neuronen pro Schicht, wobei der bias ausgeschlossen ist.
Die Gewichte $\omega_{ij}^{l}$ geben an, in welcher Relation die Neuronen der vorherigen Schicht $l-1$ zu den Neuronen der
nächsten Schicht $l$ stehen. Dabei werden die Gewichte der Bias-Neuronen mit $b_j^{(l)}:= \omega_{0j}^{(l)}$ von den
anderen Gewichten unterschieden.
\begin{figure}[htp]
    \centering
    \begin{neuralnetwork}[height=4]
        \newcommand{\x}[2]{$x^{(0)}_#2$}
        \newcommand{\y}[2]{$y_#2$}
        \newcommand{\hfirst}[2]{\small $x^{(1)}_#2$}
        \newcommand{\hsecond}[2]{\small $x^{(2)}_#2$}
        \inputlayer[count=3, bias=true, title=Eingabe-\\schicht, text=\x]
        \hiddenlayer[count=3, bias=true, title=versteckte\\Schicht 1, text=\hfirst]
        \linklayers
        \hiddenlayer[count=3, bias=true, title=versteckte\\Schicht 2, text=\hsecond]
        \linklayers
        \outputlayer[count=2, title=Ausgabe-\\schicht, text=\y] \linklayers
    \end{neuralnetwork}
    \caption{neuronales Netzwerk mit 3 Eingabeneuronen (grün), bias (gelb), zwei versteckte Schichten
        (blau) und 2 Ausgabeneuronen (rot)}
    \label{neuralNetexample}
\end{figure}
!! TODO: Frage ob ich das mit Seminararbeit citen muss !!\\
Die Signale der Neuronen ab der ersten versteckten Schicht bilden sich aus der Summe aller vorherigen
Signale mit ensprechender Gewichtung:
\[
    s_j^{(l)} = \sum_{i=1}^{n^{(l)}} \omega_{ij}^{(l)} x_i^{(l-1)} - b_j^{(l)}.
\]
Darauffolgend ergeben sich die Ausgaben der nächsten Schicht $l$
\[
    x_j^{(l)}=\Psi(s_j^{(l)}).
\]
Dabei ist $\Psi: \mathbb{R} \rightarrow \mathbb{R}$ die sogenannte \textit{Aktivierungsfunktion}. Das Trainieren eines
neuronalen Netzes lässt sich im Grunde auf ein Minimierungsproblem einer \textit{Kostenfunktion}
\[
    C: \mathbb{R}^{\left(n^{(l-1)} + 1\right) \times n^{(l)} \times L} \rightarrow \mathbb{R}
\]
reduzieren. Dazu werden die Konzepte der Forward- und Backwardpropagation, sowie ein \textit{Gradientenverfahren}
benötigt, wofür auf \cite[6.2.6]{ovidiucalinDeepLearningArchitectures} verwiesen wird. Zusammengefasst werden die
Gewichte durch ein Gradientenverfahren angepasst, sodass die Kostenfunktion minimiert wird. In unserer Anwendung werden
wir hauptsächlich den \textit{Tangens hyperbolicus}
\[
    tanh(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}
\]
als Aktivierungsfunktion nutzen. Die Kostenfunktion werden wir in Abschnitt \eqref{subsec:lsgpakete} betrachten. Unser
Fokus der Gradientenverfahren wird auf der \textit{Adam} (engl. Adaptive moment Estimation) liegen. Sei
$g_k = \nabla C(\omega^{[k]})$ der Gradient der Kostenfunktion nach den Gewichten (inklusive bias) in der $k$-ten
Iteration. Dann ist das Adams-Verfahren mit den Variablen $\beta_1,\beta_2 \in [0,1)$ und den Momenten $m(0)=0$,
$v(0)=0$
\begin{align*}
    m(k) &= \beta_1 m(k-1) + (1-\beta_1)g_k \\
    v(k) &= \beta_2 v(k-1) + (1-\beta_2)(g_k)^2
\end{align*}
und deren Korrekturen
\begin{align*}
    \hat{m}(k) &= \frac{m(k)}{(1-\beta_1^k)} \\
    \hat{v}(t) &= \frac{v(k)}{(1-\beta_2^k)}
\end{align*}
gegeben durch
\[
    x(k+1) = x(k) - \eta \frac{\hat{m}(k)}{\sqrt(|\hat{v}(k)|) + \epsilon}.
\]
Dabei ist $\eta > 0$ die sogenannte \textit{learning rate} und $\epsilon > 0$ verhindert eine Division durch $0$. Eine
Voreinstellung der Parameter wäre Beispielsweise $\beta_1=0.9$, $\beta_2=0.99$, $\epsilon=10^{-8}$ und $\eta = 0.001$.
Zu Beginn ($k=0$) müssen jedoch schon Gewichte gegeben sein, um $g_k$ berechnen zu können. Die Frage zur sinnvollen
Initialisierung der Gewichte zu Beginn des Trainings werden wir im Abschnitt\eqref{subsec:gewichtsinitialisierung}
genauer betrachten.

\subsection{Prinzip der Lösungspakete}
\label{subsec:lsgpakete}

\subsection{Gewichtsinitialisierung}
\label{subsec:gewichtsinitialisierung}




\subsection{curriculum learning}
\label{subsec:curriculum-learning}