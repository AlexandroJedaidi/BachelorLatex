\section{Numerischer Lösungsansatz}
Dieses Kapitel beruht im Wesentlichen auf \cite{peterdeuflhardfolkmarbornemannNumerischeMathematikGewohnliche},
\cite{ernsthairergerhardwannerSolvingOrdinaryDifferential} und \cite{prof.dr.josefstoerNumerischeMathematik}. Wir
werden uns im Folgenden hauptsächlich das
Anfangswertproblem
\begin{align}
    \label{first-order-num}
    x^{\prime} &= f(t,x) \nonumber \\
    x(t_0) &= x_0
\end{align}
betrachten, wobei $f$ stetig ist.\\
Unser Ziel ist es, eine effektive Methode zu verwenden, um eine Lösung eines Anfangswertproblem finden zu können.
Da es nicht immer möglich ist, eine gewöhnliche Differentialgleichung analytisch zu lösen, gibt es sogenannte Ein- und
Mehrschrittverfahren, welche  eine Lösung der gewöhnliche Differentialgleichung approximiert.
Der Grundgedanke dieser Verfahren ist es das Zeitintervall $D=[t_0,t_{0}+a]$ zu diskretisieren
$t_0 < t_1 < \dots < t_N = t_{0}+a$ und beginnend mit dem Anfangswert $t_0$ eine Näherung $u_i \approx x(t_i)$ für
$i=0, \dots, N$ berechnet. Solche Verfahren werden mit Hilfe von Quadraturformeln der numerischen Integration
\cite[Numerische Integration]{walzLexikonMathematik} hergeleitet.\\
Dies basiert darauf, dass die Differentialgleichung auf einem Teilintervall $[t_i, t_{i+1}] \subset D$
integriert wird und nach dem Hauptsatz der Differential- und Integralrechung auf folgende Gleichung gebracht werden kann:
\[
    x(t_{i+1}) - x(t_i) = \int_{t_i}^{t_{i+1}} x^{\prime}(t)dt = \int_{t_i}^{t_{i+1}}f(t, x(t))dt.
\]
Das Integral kann nun mit einer bereits genannten Quadraturformel approximiert werden, welches je nach Wahl der
Quadraturformel ein Einschrittverfahren bildet.
\subsection{Einschrittverfahren}
In diesem Abschnitt betrachten wir die Einschrittverfahren.
\begin{definition}
    Sei $D=[t_0,t_0+\alpha]$ ein Zeitintervall und eine Zerlegung $D_h=\{t_i=t_0 + ih \text{ für } i=0, \dots,N\}$ von D mit der
    Schrittweite $h=\frac{a}{N}$.
    Ein {\em explizites Einschrittverfahren} für das Anfangswertproblem \eqref{first-order-num} hat die Form
    \begin{align}
        u_0 &= x_0 \nonumber \\
        u_{i+1} &= u_i + h \phi(t_i,u_i,h,f), \quad i=0,\dots,N-1. \label{eq:6}
    \end{align}
    Dabei nennt man
    $\phi:D_h \times \mathbb{R}^n \times \mathbb{R} \times C(D \times K,\mathbb{R}^n) \rightarrow \mathbb{R}^n$ die
    Inkrementfunktion, wobei $K \subseteq \mathbb{R}^n$.
    {\em Implizite Einschrittverfahren} haben die Form
    \begin{align*}
        u_0 &= x_0\\
        u_{i+1} &= u_i + h\phi(t_i,u_i,u_{i+1},h,f), \quad i=0,\dots,N-1,
    \end{align*}
    mit $\phi:D_h \times \mathbb{R}^n \times \mathbb{R}^n \times \mathbb{R} \times C(D \times K,\mathbb{R}^n)
    \rightarrow \mathbb{R}^n$.
\end{definition}
Zur Analyse der Approximationsqualität der Einschrittverfahren werden neue Begriffe erläutert.
\begin{definition}[Lokaler Diskretisierungsfehler]
    Sei das Anfangswertproblem \eqref{first-order-num} mit \\ Lipschitz-stetiger
    rechten Seite und ein explizites Einschrittverfahren \eqref{eq:6} gegeben. Für $\hat{t}\in [t_0,t_0+a]$ und
    $0 < h < t_0 + a - \hat{t}$ ist der {\em lokale Diskretisierungsfehler} definiert als
    \[
        \tau(\hat{t}, h) := \frac{x(\hat{t} + h) - u_1(\hat{t})}{h},
    \] wobei $u_1(\hat{t})=x(\hat{t}) + h\phi\left(\hat{t},x(\hat{t}\right),h,f) $ die Approximation der exakten
    Lösung nach einem Schritt mit $x(\hat{t})$ als Startpunkt ist.\\
    Falls zusätzlich für alle f mit stetiger und beschränkter Ableitung (bis zur Ordnung p) in der x-Variable gilt, dass
    für alle $\hat{t} \in (t_0, t_0+a]$
    \[
        \lim_{h \rightarrow 0 } \tau(\hat{t}, h)=0 \quad (\tau(\hat{t},h) = \mathcal{O}(h^p) \text{ für } h \rightarrow 0),
    \] dann nennt man das Einschrittverfahren {\em konsistent} {\em (von der Ordnung p)}.
\end{definition}
\begin{definition}[Globaler Diskretisierungsfehler]
    Mit $\hat{t} = t_i = t_0+ih, i=1,\dots, N$ ist der {\em globale Diskretisierungsfehler} definiert als
    \[
        e(\hat{t}, h) := x(\hat{t}) - u_i,
    \]
    wobei $u_i$ die vom Einschrittverfahren approximierte Lösung im $i$-ten Schritt ist.\\
    Falls zusätzlich für alle f mit stetiger und beschränkter Ableitung (bis zur Ordnung p) in der x-Variable gilt, dass
    für alle $\hat{t} \in (t_0, t_0+a]$
    \[
        \lim_{h \rightarrow 0 } e(\hat{t}, h)=0 \quad (e(\hat{t},h) = \mathcal{O}(h^p) \text{ für } h \rightarrow 0),
    \] dann nennt man das Einschrittverfahren {\em konvergent} {\em (von der Ordnung p)}.
\end{definition}
Es ist uns möglich, eine obere Schranke für den globalen Fehler zu finden. Dazu müssen wir zuerst die diskrete Version
der Gronwallsche Ungleichung \ref{Satz-gronwall} beweisen.
\begin{satz}[Diskrete Gronwallsche Ungleichung]
    Gegeben seien die Folgen $(\alpha)_i,(\beta)_i,(\gamma)_i \geq 0$ mit $i = 0,\dots,N$ und es gilt
    \[
        \gamma_{i+1} \leq (1 + \alpha_i)\gamma_i + \beta_i, \quad i=0,\dots,N-1.
    \] Dann gilt
    \[
        \gamma_{i+1} \leq \left( \gamma_0 + \sum_{j=0}^{i}\beta_j \right) e^{\alpha_0 + \dots + \alpha_i},  \quad
        i=0, \dots, N-1.
    \]
\end{satz}
$Beweis.$ Wir beweisen diesen Satz mittels Induktion nach $i$:
\begin{alignat*}{2}
    (i=0):& \qquad \gamma_1 &&\leq
    \underbrace{(1 + \alpha_0)}_{\leq e^{\alpha_0}}\gamma_0 +
    \underbrace{\beta_0}_{=\beta_0 e^{0} \leq \beta_0 e^{\alpha_0}} \leq (\gamma_0 + \beta_0)e^{\alpha_0},\\
    (\text{IV}):& \qquad
    \gamma_{i} &&\leq \left( \gamma_0 + \sum_{j=0}^{i-1}\beta_j \right) e^{\alpha_0 + \dots + \alpha_{i-1}} \\
    (i \rightarrow i+1):& \quad
    \gamma_{i+1} &&\leq (1 + \alpha_{i})\gamma_{i} + \beta_i\\
    & &&\underset{\text{IV}}{\leq} (1 + \alpha_i)
    \left( \gamma_0 + \sum_{j=0}^{i-1}\beta_j \right) e^{\alpha_0 + \dots + \alpha_{i-1}}+\beta_{i}\\
    &  &&\leq e^{\alpha_i} \left( \gamma_0 + \sum_{j=0}^{i-1}\beta_j \right) e^{\alpha_0 + \dots + \alpha_{i-1}}
    + \beta_i e^{\alpha_0 + \dots + \alpha_{i}}\\
    &  &&\leq \left( \gamma_0 +  \sum_{j=0}^{i}\beta_j \right) e^{\alpha_0 + \dots + \alpha_{i}}.
\end{alignat*}\qedwhite\\
\begin{satz}
    \label{one-step-error-bound}
    Sei das Einschrittverfahren \eqref{eq:6} und das Anfangswertproblem \eqref{first-order-num} gegeben. Ist  die
    Inkrementfunktion $\phi$ in der $x-Variable$ Lipschitz-stetig, also
    \[
        \left\lVert \phi(t, x_1, h, f) - \phi(t, x_2, h, f) \right\rVert_2 \leq L \left\lVert x_1 - x_2 \right\rVert_2
    \]
    für alle $(t, x_1, h),(t, x_2, h) \in D \times \mathbb{R}^n \times [0, h_0]$ mit $h_0, L>0$, dann gilt für den
    globalen Fehler in $t_i = t_0 + ih$ die obere Schranke
    \[
        \left\lVert e(t_i,h) \right\rVert_2 \leq \left( \left\lVert e_0 \right\rVert_2 + (t_i-t_0)\tau_h \right)
        e^{L(t_i-t_0)}, \quad i = 1, \dots, N.
    \]
    Dabei ist $e_0 = x(t_0)-u_0$ und $\tau_h= \max\limits_{k=1,\dots,N} \left\lVert \tau(t_k,h) \right\rVert_2 $.
\end{satz}
$Beweis.$ Löse zuerst die Gleichung des lokalen Diskretisierungsfehlers auf $x(t_{j+1})$ auf:
\[
    x(t_{j+1}) = x(t_j) + h \phi(t_j, x(t_j),h,f) + h \tau(t_j, h), \quad j = 0, \dots , i-1.
\]
Dann nutzen wir das Ergebnis für den globalen Fehler
\[
    e(t_{j+1},h) = x(t_{j+1}) - u_{j+1} = x(t_j) - u_j + h \tau(t_j, h)
    + h \left( \phi(t_j, x(t_j),h,f) - \phi(t_j, u_j, h, f) \right)
\]
und schätzen ab
\[
    \left\lVert e(t_{j+1},h) \right\rVert_2 \leq \left\lVert e(t_j, h) \right\rVert_2 + h\tau_h
    + hL\left\lVert e(t_j,h) \right\rVert_2 = (1 + hL) \left\lVert e(t_j,h) \right\rVert_2 + h\tau_h.
\]
Nun können wir mit $\alpha_j=hL$, $\gamma_j =\left\lVert e(t_j,h) \right\rVert_2$ und $\beta_j = h\tau_h$ die diskrete
Gronwallsche Ungleichung anwenden und erhalten
\begin{align*}
    \left\lVert e(t_{j+1},h) \right\rVert_2
    &\leq ( \left\lVert e_0 \right\rVert_2 + \sum_{i=0}^{j} h\tau_h ) e^{\sum_{i=0}^{j} hL } \\
    &= \left( \left\lVert e_0 \right\rVert_2 + (j+1)h \tau_h \right)e^{(j+1)hL} \\
    &= \left( \left\lVert e_0 \right\rVert_2 + (t_{j+1} - t_0) \tau_h \right)e^{L(t_{j+1} - t_0)} \\
\end{align*}
für alle $j=0, \dots, i-1$, also insbesondere
\[
    \left\lVert e(t_{i},h) \right\rVert_2
    = \left( \left\lVert e_0 \right\rVert_2 + (t_{i} - t_0) \tau_h \right)e^{L(t_{i} - t_0)}
\]
für $j=i-1$.\qedwhite\\
Der Satz besagt also, dass die Konsistenz des Einschrittverfahrens bereits die Konvergenz impliziert. Im allgemeinen ist
ein Verfahren genau dann konvergent, wenn es konsistent und stabil ist, wie wir später beweisen werden.

\subsection{Runge-Kutta-Verfahren}
Runge-Kutta-Verfahren sind Einschrittverfahren höherer Ordnung. Um ein Runge-Kutta-Verfahren herleiten zu können, müssen
wir zuerst definieren, was eine Quadraturformel ist.
\begin{definition}
    Eine Quadratur ist eine Abbildung $Q_n: C([a,b])\rightarrow \mathbb{R}$, für die gilt
    \[
        Q_m(g) = (b-a)\sum_{l=1}^{m}\alpha_l g(s_l) \quad \text{ für alle } g\in C([a,b]),
    \]
    wobei $\Delta = \{a=s_1, \dots, s_m=b\}$ eine Intervallunterteilung ist. Die Zahlen $s_1, \dots, s_m$ heißen Stützstellen und
    $\alpha_1, \dots, \alpha_m$ heißen Gewichte der Quadratur.\\
    Für eine interpolatorische Quadratur gilt zusätzlich
    \[
        \alpha_l = \int_{0}^{1} \prod_{\underset{j\neq l}{j=1}}^{m} \frac{t-t_j}{t_i-t_j} dt,
        \quad t_j = \frac{s_j-a}{b-a}.
    \]
\end{definition}
In unserem Fall ist $(b-a)=t_{i+1}-t_i=h$, da wir das Integral $\int_{t_i}^{t_{i+1}} f(s,x(s))ds$ mit einer Quadratur
approximieren:
\[
    \int_{t_i}^{t_{i+1}} f(s,x(s))ds \approx h \sum_{l=1}^{m}\alpha_l f(s_l,x(s_l)).
\]
Die Stützstellen sind also $s_1=t_i$, $s_l=t_i+c_{l} h$ für $l = 2,\dots, m$. Dazu approximieren wir
$f(s_l,x(s_l))\approx k_{l,i}$ mit
\begin{align}
    k_{1,i} &= f(t_i,u_i) \nonumber \\
    k_{l,i} &= f(t_i+c_lh, u_i + h\sum_{j=1}^{l-1}a_{lj}k_{j,i} ), \quad l=2,\dots,m.   \label{eq:rk}
\end{align}

Dies ergibt das $m$-stufige explizite Runge-Kutta-Verfahren
\begin{align}
    u_{i+1} = u_i + h \sum_{l=1}^{m} b_l k_{l,i},   \label{exp-rk-def}
\end{align}
mit $b_1, \dots, b_m \in \mathbb{R}$
Wir werden später ein klassisches $4$-stufiges Runge-Kutta-Verfahren verwenden, welches wir jetzt herleiten.
Dazu benötigen wir die Simpsonregel
\[
    Q_3(g) = \frac{b-a}{6} (g(a) + 4g(\frac{a+b}{2}) +g(b)).
\]
Es gilt also die Approximation
TODO: Taylor Entwicklung
\begin{align*}
    \int_{t_i}^{t_{i+1}} f(s,x(s)) ds &\approx
    \frac{h}{6}(f(t_i,x(t_i)) + 4f((t_i + \frac{h}{2}), x(t_i+\frac{h}{2})) + f(t_i + h,x(t_i + h))) \\
    &= h\left(\frac{1}{6}f(t_i,x(t_i)) + \frac{2}{3}f\left( t_i + \frac{h}{2}, x\left( t_i + \frac{h}{2}\right) \right)
    + \frac{1}{6}f(t_{i+1},x(t_{i+1}))\right). \\
\end{align*}
%Nun können wir $x(t_i+\frac{h}{2})$ mit einem Schritt des Euler-Verfahrens
%\[
%    x(t_i+\frac{h}{2}) \approx u_i + \frac{h}{2} f(t_i, u_i)
%\]
%und $x(t_{i+1})$ mit Hilfe der Taylor-Entwicklung abschätzen
%\[
%    x(t_{i+1}) = x(t_i) + hf(t_i,x(t_i)) + \frac{h}{2} x^{\prime \prime}(t_i)\mathcal{O}(h^2)
%\]
%\[
%    h\left(\frac{1}{6}f(t_i,x(t_i)) + \frac{2}{3}f\left( t_i + \frac{h}{2}, x\left( t_i + \frac{h}{2}\right) \right)
%    + \frac{1}{6}f(t_{i+1},x(t_{i+1}))\right).
%\]
Damit ergibt sich durch mehrfacher Anwendung der Taylor-Entwicklung das 4-stufige klassische Runge-Kutta-Verfahren
\[
    u_{i+1} = u_i + h\left( \frac{1}{6}k_{1,i} + \frac{1}{3} k_{2,i} + \frac{1}{3} k_{3,i} + \frac{1}{6} k_{4,i} \right)
\]
mit den Stufen
\begin{align*}
    k_{1,i} &= f(t_i,u_i), \\
    k_{2,i} &= f(t_i + \frac{h}{2}, u_i + \frac{h}{2}k_{1,i}), \\
    k_{3,i} &= f(t_i + \frac{h}{2}, u_i + \frac{h}{2}k_{2,i}), \\
    k_{4,i} &= f(t_i + \frac{h}{2}, u_i + \frac{h}{2}k_{3,i}). \\
\end{align*}
In diesem Fall haben wir die Koeffizienten
\[
    b := \left( b_1, \dots , b_m \right)^{\intercal}
    =\left( \begin{matrix}
                \frac{1}{6}\\
                \frac{1}{3}\\
                \frac{1}{3}\\
                \frac{1}{6}\\
    \end{matrix}\right), \quad
    c := \left( c_1, \dots, c_m \right)^{\intercal}
    = \left( \begin{matrix}
                 0\\
                 \frac{1}{2}\\
                 \frac{1}{2}\\
                 1\\
    \end{matrix} \right), \quad
    A:=[a_{lj}]_{l,j=1}^{m,m} = \left( \begin{matrix}
                             0 & 0 & 0 & 0\\
                             \frac{1}{2} & 0 & 0 & 0 \\
                             0 & \frac{1}{2} & 0 & 0 \\
                             0 & 0 & 1 & 0\\
    \end{matrix} \right).
\]
Im Allgemeinen gilt für explizite Runge-Kutta-Verfahren, dass $a_{lj} = 0$ für $l \leq j$.\\
\begin{bem}
    Die Koeffizienten charakterisieren ein Runge-Kutta-Verfahren, weshalb sie für üblich in sogenannten
    $Butcher$- $Tabellen$ zusammengefasst werden:
    \begin{center}
        \begin{tabular}{c | c}
            c & A \\
            \hline
            & $b^{\intercal}$
        \end{tabular}
    \end{center}
\end{bem}
Da Runge-Kutta-Verfahren Einschrittverfahren sind, gibt es auch implizite Runge-Kutta-Verfahren mit der Form
\begin{align*}
    k_{1,i} &= f(t_i+c_1h, u_i + h(a_{11}k_{1,i} + \dots + a_{1m} k_{m,i})) \\
    &\vdots\\
    k_{m,i} &= f(t_i+c_mh, u_i + h(a_{m1}k_{1,i} + \dots + a_{mm} k_{m,i}))\\
    u_{i+1} &= u_i + h(b_1 k_{1,i} + \dots + b_m k_{m,i})
\end{align*}
Hier kann $A$ im Gegensatz zu expliziten Runge-Kutta-Verfahren eine volle Matrix sein.

\subsubsection{Konsistenz}
Es wurde bereits gezeigt, dass die Konvergenz eines Einschrittverfahrens aus der Konsistenz folgt. Deshalb genügt es
sich die Konsistenz(ordnung) der Runge-Kutta-Verfahren zu betrachten. Dabei spielt die Wahl der Koeffizienten eine
große Rolle. Ziel ist es, die Koeffizienten so zu wählen, dass die Konsistenzordnung des Runge-Kutta-Verfahrens
möglichst hoch ist. Dazu zeigen wir zuerst, dass unter bestimmten Voraussetzungen für die Koeffizienen ein explizites
Runge-Kutta-Verfahren invariant gegenüber Autonomisierung ist. Das bedeutet, dass ein Runge-Kutta-Verfahren genau dann
ein Anfangswertproblem \eqref{first-order-num} mit der Näherungslösung $u_i$ approximiert, wenn es das autonomisierte
Anfangswertproblem
\begin{alignat}{3}
    \label{autonom-awp}
    z^{\prime} &= 1, \qquad &z(t_0) &= t_0, \\
    x^{\prime} &= f(z,x),\qquad  &x(t_0) &= x_0 \nonumber \\ \nonumber
\end{alignat}
mit der Näherungslösung $v_i := \left[ \begin{matrix}
                                           t_i\\
                                           u_i\\
\end{matrix} \right]$
approximiert.
\begin{satz}
    Gegeben sei ein explizites Runge-Kutta-Verfahren \eqref{exp-rk-def}. Dies ist genau dann invariant gegenüber
    Autonomisierung, wenn für die Koeffizienten gilt:
    \[
        \sum_{j=1}^{m} b_j = 1 \qquad \text{und} \qquad c_l=\sum_{j=1}^{l-1} a_{lj}, \quad l = 1, \dots, m.
    \]
\end{satz}
$Beweis.$ Für ein autonomes Anfangswertproblem \eqref{autonom-awp} hat das Runge-Kutta-Verfahren die Form
\begin{alignat*}{2}
    \hat{k}_{l,i} &= \begin{bmatrix} \hat{k}^{z}_{l,i} \\ \hat{k}^{x}_{l,i} \end{bmatrix}
    = \begin{bmatrix} 1 \\
    f\left( t_i + h \sum\limits_{j=1}^{l-1} a_{lj} \cdot \hat{k}^{z}_{j,i},
    u_i + h \sum\limits_{j=1}^{l-1} a_{lj} \hat{k}^{x}_{j,i} \right)
    \end{bmatrix},  \quad l=1,\dots,m, \\
    v_{i+1} &= v_i + h \sum\limits_{l=1}^{m} b_l \hat{k}_{l,i} = \begin{bmatrix}
                                                                     t_i + h \sum\limits_{l=1}^{m} b_l \cdot 1\\
                                                                     u_i + h \sum\limits_{l=1}^{m} b_l \hat{k}^{x}_{l,i}
    \end{bmatrix}
    \overset{!}{=}\begin{bmatrix}t_{i+1}\\u_{i+1}\\\end{bmatrix}.
\end{alignat*}
Es gilt also genau dann $t_i + h \sum\limits_{l=1}^{m} b_l \cdot 1 = t_{i+1}$, wenn $\sum\limits_{l=1}^{m} b_l = 1$.
Für die zweite Komponente gilt genau dann $u_i + h \sum\limits_{l=1}^{m} b_l \hat{k}^{x}_{l,i} = u_{i+1}$,
wenn $\hat{k}^{x}_{l,i} = k_{l,i}$, $l = 1, \dots, m$. Äquivalent dazu muss gelten
\[
    f\left( t_i + h \sum\limits_{j=1}^{l-1} a_{lj} \cdot 1,
    u_i + h \sum\limits_{j=1}^{l-1} a_{lj} \hat{k}^{x}_{j,i} \right)
    = f\left( t_i +hc_l, u_i + h \sum_{j=1}^{l-1} a_{lj} k_{j,i} \right), \quad l = 1, \dots, m,
\]
was genau dann erfüllt ist, wenn $c_l = \sum\limits_{o=1}^{l-1} a_{lo}, \quad l= 1, \dots, m.$ \qedwhite\\
Im Folgenden werden wir uns auf autonome Anfangswertprobleme der Form
\begin{align}
    x^{\prime} = f(x), \quad x(t_0) = x_0   \label{eq:9}
\end{align}
beschränken. Unser Ziel ist es Voraussetzungen an die Koeffizienten des Runge-Kutta-Verfahrens zu setzen, so dass wir eine
größtmögliche Konsistenzordnung erhalten. Dazu betrachten wir den lokalen Diskretisierungsfehler
\begin{align}
    \tau (t_i,h) &= \frac{x(t_i + h) - x(t_i)}{h} - \phi(t_i, x(t_i), h, f) \nonumber \\
    &= \frac{x(t_i + h) - x(t_i)}{h} - \sum_{l=1}^{m} b_l k_{l,i}.  \label{eq:kon_auto}
\end{align}
Wenden wir nun die Taylorentwicklung auf die exakte Lösung $x$ für das Anfangswertproblem \eqref{eq:9} an, erhalten wir
\begin{align*}
    x(t_{i+1}) &= x(t_i) + hx^{\prime}(t_i) + \frac{1}{2} h^2 x^{\prime \prime}(t_i) + \mathcal{O}(h^3) \\
    &= x(t_i) + hf(x(t_i)) + \frac{1}{2} h^2 Df(x(t_i)) f(x(t_i)) + \mathcal{O}(h^3),\\
\end{align*}
wobei für die Ableitungen der Lösung $x$ die Kettenregel benutzt wird
\begin{align*}
    x^{\prime}(t_i) &= f(x(t_i)),\\
    x^{\prime \prime}(t_i) &= Df(x(t_i))x^{\prime}(t_i) = Df(x(t_i))f(x(t_i))\\
\end{align*}
und $Df(x(t_i))$ die Jacobi-Matrix von $f$ in $x(t_i)$ ist. Da wir uns nur auf das autonome Anfangswertproblem
\eqref{eq:9} beschränken, hat das explizite Runge-Kutta-Verfahren die Stufen
\begin{align*}
    k_{i,1} &= f(x(t_i)), \\
    k_{i,2} &= f(x(t_i) + ha_{21}k_{1,i}), \\
    &\vdots\\
    k_{i,m} &= f(x(t_i) + ha_{m1}k_{1,i} + \dots + ha_{m,m-1}k_{m-1,i}).\\
\end{align*}
!!TODO: schöner machen!!\\
Nun wenden ähnlich wie oben die Taylorentwicklung im Punkt $x(t_i)$ an und erhalten
\begin{align*}
    k_{i,1} &= f(x(t_i)), \\
    k_{i,2} &= f(x(t_i)) + ha_{21}Df(x(t_i))k_{1,i} + \mathcal{O}(h^2), \\
    &\vdots\\
    k_{i,m} &= f(x(t_i)) + ha_{m1}Df(x(t_i))k_{1,i} + \dots + ha_{m,m-1}Df(x(t_i))k_{m-1,i} + \mathcal{O}(h^2). \\
\end{align*}
Im nächsten Schritt setzen wir die Stufen sukzessive ein und verwenden
\[
    h k_{j,i} = hf(x(t_i)) + h^2 a_{j-1,l}Df(x(t_i))f(x(t_i)) + \mathcal{O}(h^2) = hf(x(t_i)) + \mathcal{O}(h^2),
\]
\begin{align*}
    k_{i,1} &= f(x(t_i)), \\
    k_{i,2} &= f(x(t_i)) + ha_{21}Df(x(t_i))f(x(t_i)) + \mathcal{O}(h^2), \\
    &\vdots\\
    k_{i,m} &= f(x(t_i)) + ha_{m1}Df(x(t_i))f(x(t_i)) + \dots + ha_{m,m-1}Df(x(t_i))f(x(t_i)) + \mathcal{O}(h^2). \\
\end{align*}
Einsetzen in \eqref{eq:kon_auto} ergibt
\begin{align*}
    \tau(t_i,h) &= f(x(t_i)) + \frac{1}{2}hD(f(x(t_i)))f(x(t_i)) + \mathcal{O}(h^2) \\
    &- \sum_{l=1}^{m} b_l \left( f(x(t_i)) + h \sum_{j=1}^{l-1} a_{lj} D(f(x(t_i)))f(x(t_i)) + \mathcal{O}(h^2)\right)\\
    &= \left( 1 - \sum_{l=1}^{m} b_l  \right)f(x(t_i))
    + h \left( \frac{1}{2} - \sum_{l=1}^{m} \sum_{j=1}^{l-1} b_l a_lj \right) Df(x(t_i))f(x(t_i)) + \mathcal{O}(h^2).
\end{align*}
Da $\sum\limits_{l=1}^{m}b_l =1$ gilt, kann schnell abgelesen werden, dass für die gegenüber Autonomisierung invariante
Runge-Kutta-Verfahren die Konsistenzordnung $p=1$ gilt. Außerdem bilden sich weitere Voraussetungen für höhere
Konsistenzordnungen, wie beispielsweise für $p=2$:
\[
    \sum_{l=1}^{m} \sum_{j=1}^{l-1} b_l a_{lj} = \sum_{l=1}^{m} b_l c_l = \frac{1}{2}.
\]
Allgemein lassen sich für höhere Konsistenzordnungen weitere Voraussetzung durch Taylorentwicklungen mit höheren
$h$-Potenzen finden.
\begin{satz}[Butcherschranken]
    Für die maximale erreichbare Ordnung $p$ eines expliziten Runge-Kutta-Verfahrens mit $m$ Stufen gilt
    \[
        p \leq m.
    \]
    Außerdem kann man folgende Abschätzungen finden\\
    \begin{center}
        \begin{tabular}{ c | c | c }
            Stufe $m$ & 1 \quad 2 \quad 3 \quad 4 \quad 5 \quad 6 \quad 7 \quad 8 \quad 9 & \quad $\geq 9$ \\
            \hline
            Ordnung p & 1 \quad 2 \quad 3 \quad 4 \quad 4 \quad 5 \quad 6 \quad 6 \quad 7 & \quad  $\leq m-2$
        \end{tabular}
    \end{center}
\end{satz}
$Beweis.$ ($p\leq m$ Behauptung) \cite[173-174]{ernsthairergerhardwannerSolvingOrdinaryDifferential}

\subsubsection{Schrittweitensteuerung}
Wir haben im letzten Abschnitt gesehen, unter welchen Bedingungen die Konvergenz der Runge-Kutta-Verfahren die exakte
Lösung der gegebenen Differentialgleichung gewährleistet ist. Unser Ziel ist es nun die bisher konstante Schritteweite
$h$ so zu wählen, dass der Rechenaufand zur Approximation der Lösung so gering wie möglich gehalten wird.
Dazu gibt es im Grunde zwei Fälle:\\
Ist der lokale Disktretisierungsfehler größer als eine gegebene Toleranz, so sollten wir die Schrittweite verkleinern,
um den Fehler zu verringern. Ein Beispiel hierfür wäre eine oszillierende Lösung, bei der eine zu große Schrittweite
zu hohem lokalen Fehler führen würde, da das Einschrittverfahren Wendungspunkte überspringen würde.
Ist der lokale Diskretisierungsfehler aber klein in Relation zur Toleranz, dann können wir die Schrittweite
vergrößern, um den Rechenaufwand zu minimieren. Dies tritt beispielsweise bei nahezu linearen Lösungsfunktionen auf. \\
Also müssen wir uns zuerst überlegen, wie wir den lokalen Diskretisierungsfehler sinnvoll mit minimalen Rechenaufwand
abschätzen, ohne die tatsächliche Lösung der Differentialgleichung zu kennen. Dazu verwenden wir sogenannte
$eingebettete$ $Runge$-$Kutta$-$Verfahren$, welche aus zwei Einschrittverfahren
\[
    u_{i+1}^{(1)} = u_i + h_i \phi_{p}(t_i,u_i,h_i,f)
\]
und
\[
    u_{i+1}^{(2)} = u_i + h_i \phi_{p+1}(t_i,u_i,h_i,f)
\]
mit den Konsistenzordnungen $p$ und $p+1$ bestehen. Die Butcherschranken implizieren, dass die Anzahl
der Stufen schneller steigt, als die Konsistenzordnung, weshalb es nur bis zu einem gewissen Grad sinnvoll ist, ein
Runge-Kutta-Verfahren höherer Ordnung für $u^{(2)}$ zu verwenden. Deshalb beschränken wir uns auf Verfahren mit
Konsistenzordnung $p+1$.
Das Verfahren nennt man $eingebettet$, wenn die für $u_i^{(1)}$ berechneten Stufen bei der Berechnung von $u_i^{(2)}$
wieder verwendet werden. Dabei werden Funktionsauswertungen gespart, was den Rechenaufwand und die Laufzeit reduziert.
Die dazugehörige Butcher-Tabelle wird dementsprechend zu einer $kombinierten$ Butcher-Tabelle erweitert
\begin{center}
    \begin{tabular}{c | c}
        $c$ & $A$ \\
        \hline
        & $(b^{(1)})^{\intercal}$ \\
        \hline
        & $(b^{(2)})^{\intercal}$
    \end{tabular}
\end{center}
Dabei ist $b^{(1)}$ der Koeffizientenvektor für von $u_{i+1}^{(1)}$ und $b^{(2)}$ Koeffizientenvektor für
$u_{i+1}^{(2)}$.\\
Wir definieren
\begin{align*}
    \Delta_{p} &:= x(t_i + h_i) - u^{(1)}_{i+1}
    = x(t_i + h_i) - u_i - h_i \Phi_{p}(t_i,u_i,h_i,f)= h_i\tau^{(1)}(t_i,h_i) = \mathcal{O}(h_i^{p+1}),\\
    \Delta_{p+1} &:= x(t_i + h_i) - u^{(2)}_{i+1}
    = x(t_i + h_i) - u_i - h_i \Phi_{p+1}(t_i,u_i,h_i,f)= h_i\tau^{(2)}(t_i,h_i)= \mathcal{O}(h_i^{p+2}).
\end{align*}
Daraus erhalten wir eine Abschätzung des lokalen Diskretisierungsfehlers mit
\begin{align*}
    h_i\tau_{p} &= \Delta_{p} = \Delta_{p+1} + h_i(\Phi_{p+1}(t_i,u_i,h_i,f) - \Phi_{p}(t_i,u_i,h_i,f)) \\
    &\approx h_i(\Phi_{p+1}(t_i,u_i,h_i,f) - \Phi_{p}(t_i,u_i,h_i,f)),
\end{align*}
da $\Delta_{p+1} \approx 0$ für kleine $h_i$ gilt. Also erhalten wird mit der alten Schrittweite $h_{\text{alt}}$
\[
    \Delta_{p, \text{alt}} \approx h_i(\Phi_{p+1}(t_i,u_i,h_i,f) - \Phi_{p}(t_i,u_i,h_i,f))
    = \left\lVert u_i^{(2)} - u_i^{(1)} \right\rVert_2.
\]

Da wir nun den lokalen Fehler abgeschätzt haben, können wir uns darum kümmern, die Schrittweite anzupassen. Sei die
Toleranz mit $\epsilon$ gegeben. Bei zu großem Fehler, also $\Delta_{p, \text{alt}} > \epsilon$, wählen wir eine neue
Schrittweite $h_{\text{neu}}$ und wiederholen den aktuellen Schritt. Unser Ziel dabei ist es, dass der neue Fehler
$\Delta_{p, \text{neu}}$ etwas kleiner ist als $\epsilon$, was mit der Approximation
$\Delta_{p, \text{neu}} \approx \rho \epsilon$ mit $0 < \rho < 1$ gesichert ist. Da
$\Delta_p = \mathcal{O}(h_i^{p+1}) \approx ch_i^{p+1}$ für jede Schrittweite gilt, kann man folgern
\begin{align*}
    \frac{\rho \epsilon}{h_{\text{neu}}^{p+1}}
    &\approx \frac{\Delta_{p, \text{neu}}}{h_{\text{neu}}^{p+1}}
    \approx c
    \approx \frac{\Delta_{p, \text{alt}}}{h_{\text{alt}}^{p+1}}\\
    \Rightarrow h_{\text{neu}} &\approx h_{\text{alt}} \sqrt[p+1]{\frac{\rho \epsilon}{\Delta_{p, \text{alt}}}}.
\end{align*}
Im anderen Fall ist der Fehler zu klein $\Delta_{p, \text{alt}} \approx 0$. Dann können wir die Schrittweite mit Hilfe
einer Hochschaltungsbeschränkung anpassen. Dabei setzen wir $h_{\text{neu}} = \min(q h_{\text{alt}}, h_{\text{max}})$,
wobei $h_{\text{max}}$ die maximale Schrittweite und $q>1$ der Hochschaltfaktor ist. Wird der Schritt akzeptiert, so
setzen wir $u_{i+1} = u_{i+1}^{(2)}$ und führen die Approximation mit der neuen Schrittweite fort.\\
Wir werden in dieser Arbeit hauptsächlich das \textit{4-5-Runge-Kutta-Verfahren} (oder \textit{Dormand-Prince-Verfahren})
mit der kombinierten Butcher-Tabelle
\begin{center}
    \begin{tabular}{c | c c c c c c c}
        0 & & & & & & & \\
        $\frac{1}{5}$ & $\frac{1}{5}$ & & & & & & \\
        $\frac{3}{10}$ & $\frac{3}{40}$ & $\frac{9}{40}$ & & & & & \\
        $\frac{4}{5}$ & $\frac{44}{45}$ & $-\frac{56}{15}$ & $\frac{32}{9}$ & & & & \\
        $\frac{8}{9}$ & $\frac{19372}{6561}$ & $-\frac{25360}{2187}$ & $\frac{64448}{6561}$ & $-\frac{212}{729}$ & & & \\
        $1$ & $\frac{9017}{3168}$ & $-\frac{355}{3}$ & $\frac{46732}{5247}$ & $\frac{49}{176}$ & $-\frac{5103}{18656}$ & & \\
        $1$ & $\frac{35}{384}$ & $0$ & $\frac{500}{1113}$ & $\frac{125}{192}$ & $-\frac{2187}{6784}$ & $\frac{11}{84}$ & \\
        \hline
        & $\frac{35}{384}$ & $0$ & $\frac{500}{1113}$ & $\frac{125}{192}$ & -$\frac{2187}{6784}$ & $\frac{11}{84}$ & $0$\\
        \hline
        & $\frac{5179}{57600}$ &  $0$ & $\frac{7571}{16695}$ & $\frac{393}{640}$ & $-\frac{92097}{339200}$
        & $\frac{187}{2100}$ & $\frac{1}{40}$ \\
    \end{tabular}
\end{center}
verwenden.

\subsection{Mehrschrittverfahren}
Durch die Butcherschranken wissen wir, dass ab einer Konsistenzordnung $p$ eines Runge-Kutta-Verfahrens immer mehr
Stufen ausgerechnet werden müssen, was wiederum eine erhöhte Anzahl an Funktionsauswertungen bedeutet. Dies wollen wir,
wenn möglich, verhindern. Deshalb führen wir sogenannte \textit{Mehrschrittverfahren} ein, welche im Gegensatz zu
Einschrittverfahren die Information aus bereits berechneten Näherungen nutzen. Mehrschrittverfahren haben also den
Vorteil, dass (zumindest explizite Verfahren) pro Schritt nur eine zusätzliche Funktionsauswertung benötigen.
\begin{definition}
    Sei $D = \left[ t_0, t_0 +a \right]$ ein Zeitintervall und die $D_h \{ t_i = t_0 + ih \text{ für } i = 0, \dots, N\}$
    Zerlegung von $D$
    \[
        t_0 < t_1 < \dots < t_N = t_0 + a
    \]
    mit der Schrittweite $h = \frac{a}{N}$. Ein {\em k-Schrittverfahren} für das Anfangswertproblem
    \eqref{first-order-num} hat die Form
    \begin{align}
        \label{k-step-method}
        &\text{Startwerte } u_0, \dots, u_{k-1}, \nonumber \\
        & \sum_{j=0}^{k} \alpha_j u_{i+j} = h \phi(t_i, u_i, \dots, u_{i+k},h,f), \quad i=0,\dots,N-k,
    \end{align}
    wobei $\alpha_k \neq 0$.
\end{definition}
Falls $\phi$ unabhängig von $u_{i+k}$, kann man \eqref{k-step-method} nach $u_{i+k}$
auflösen und hat ein explizites $k$-Schrittverfahren vorliegen. Im impliziten Fall muss man ein (nichtlineares)
Gleichungssystem lösen, um $u_{i+k}$ bestimmen zu können.\\
Die Startwerte $u_0, \dots, u_{k-1}$ können durch einmalige Verwendung von Einschrittverfahren ermittelt werden.
\begin{definition}
    Das $k$-Schrittverfahren \eqref{k-step-method} heißt {\em linear}, falls
    \begin{align}
        \label{k-step-linear}
        \sum_{j=0}^{k} \alpha_j u_{i+j} = h \sum_{j=0}^{k} \beta_j f(t_{i+j}, u_{i+j}), \quad i = 0, \dots, N-k,
    \end{align}
    gilt. Für $\beta_k = 0$ ist das Verfahren {\em explizit}, sonst {\em implizit}.
    Setzt man $\alpha_k=1$, $\alpha_{r-l}=-1$ und $\alpha_j=0$ für $j=0,\dots,k-1$, $j \neq r-l$, so erhält man ein
    \textit{lineares k-Schrittverfahren vom Typ $(r,l)$}
    \begin{align}
        \label{k-step-rl}
        u_{i+k}-u_{i+r-l} = h \sum_{j=0}^{r} \beta_j^{(r,l)} f(t_{i+j},u_{i+j}).
    \end{align}
\end{definition}
Ähnlich wie bei den Einschrittverfahren definieren wir nun zuerst den {\em lokalen Diskretisierungsfehler} der
Mehrschrittverfahren.
\begin{definition}
    Sei ein Mehrschrittverfahren \eqref{k-step-method} und das dazugehörige Anfangswertproblem \eqref{first-order-num}
    gegeben. Dann ist der {\em lokale Diskretisierungsfehler} gegeben durch
    \[
        \tau(t_i,h) = \frac{1}{h} \sum_{j=0}^{k} \alpha_j x(t_i + jh) -
        \phi (t_i,x(t_i), x(t_i+h), \dots, x(t_i+kh),h,f).
    \]
    Das Mehrschrittverfahren \eqref{k-step-method} heißt {\em kosistent von der Ordnung} $p\geq 1$, wenn für alle f mit
    stetiger und beschränkter Ableitung in der $x$-Variable bis zur Ordnung $p$ gilt, dass
    $\tau(t_i,h) = \mathcal{O}(h^p)$.
\end{definition}
Wir können unter bestimmten Bedingungen die Konsistenzordnungen der linearen Mehrschrittverfahren vom Typ $(r,l)$
\eqref{k-step-rl} explizit angeben.
\begin{satz}
    Unter den Bedingungen, dass f $(r+1)$-mal stetig differenzierbar auf $D \times K \subseteq \mathbb{R}$ ist, hat
    das lineare Mehrschrittverfahren vom Typ $(r,l)$ \eqref{k-step-rl} die Konsistenzordnung $p=r+1$.
\end{satz}
!!TODO: quelle der quelle!!
$Beweis.$ \cite[93,94]{stykelSkriptZurVorlesung2020}\\
Um die Konsistenz allgemeiner linearer k-Schrittverfahren \eqref{k-step-linear} angeben zu können, benötigen wir noch
die Definitionen für das ersten und zweiten charakteristische Polynome.
\begin{definition}
    Für ein lineares \textit{k-Schrittverfahren} \eqref{k-step-linear} sind die Polynome
    \[
        \rho(z) := \sum_{j=0}^{k} \alpha_j z^j \qquad \text{und} \qquad \sigma(z) := \sum_{j=0}^{k} \beta_j z^j
    \]
    definiert. Das Polynom $\rho(z)$ nennt man das {\em erste charakteristische Polynom} und $\sigma(z)$ das
    {\em zweite charakteristische Polynom} des gegebenen Verfahrens.
\end{definition}
Damit können wir nun folgende Aussage für die Konsistenzordnung der linearen Mehrschrittverfahen beweisen.
\begin{satz}
    Für das lineare k-Schrittverfahren \eqref{k-step-linear} sind folgende Aussagen äquivalent:
    \begin{align*}
        &\text{1. } \eqref{k-step-linear} \text{ ist konsistent von der Ordnung p.}\\
        &\text{2. Für das Anfangswertproblem }
            x^{\prime} = x, \text{ }
            x(0) = 1
        \text{ gilt } \tau(t_i,h) = \mathcal{O}(h^p).\\
        &\text{3. } \frac{\rho(z)}{\ln(z)} - \sigma(z) \text{ hat eine $p$-fache Nullstelle in } z= 1, \text{ d.h.}
            \frac{\rho(z)}{\ln(z)} - \sigma(z) = \mathcal{O}((z-1)^p) \quad \text{ für } z \rightarrow 0.\\
        &\text{4. } \sum_{j=0}^{k} \alpha_j = 0 \quad \text{ zusammen mit } \quad
        \sum_{j=0}^{k} j^m \alpha_j = \sum_{j=0}^{k} mj^{m-1} \beta_j,  \quad \text{für } m=0,1 \dots, p.
    \end{align*}\\
    Insbesondere ist für stetig differenzierbares $f$ das lineare k-Schrittverfahren \eqref{k-step-linear} konsistent,
    falls
    \[
        \rho(1) = 0 \qquad \text{ und } \qquad \rho^{\prime}(1)=\sigma(1).
    \]
\end{satz}
$Beweis.$ Wir beginnen mit $1) \Rightarrow 2)$: Wegen $1)$ ist das Verfahren schon für allgemeine gewöhnliche
Differentialgleichungen erster Ordnung konsistent also auch für den speziellen Fall. Somit gilt $2)$.\\
$2) \Rightarrow 3)$: Wir können die Lösung des Anfangsproblems in $2)$ explizit berechnen: $x(t)=e^{t}$. Jetzt können
wir den lokalen Diskretisierungsfehler angeben
\[
    \tau(t_i,h)= \frac{1}{h} \sum_{j=0}^{k} \alpha_j e^{t_i+jh} - \sum_{j=0}^{k} \beta_j e^{t_i+jh}
    = e^{t_i} \left( \frac{1}{h} \rho(e^h) - \sigma(e^{h}) \right).
\]
Es gilt $\tau(t_i,h)= \mathcal{O}(h^p) genau dann, wenn \frac{1}{h} \rho(e^h) - \sigma(e^h) = \mathcal{O}(h^p)$.
Betrachte die Taylor-Entwicklung der Funktion $\ln(z)$ mit der Entwicklungsstelle $z_0 = 1$. Dann ergibt sich
\[
    \ln z = \ln (1 + (z-1)) = \ln(1) + \mathcal{O}(z-1) = \mathcal{O}(z-1).
\]
Setzen wir nun $z=e^h oder h=\ln(z)$ und es folgt
\[
    \frac{\rho(z)}{\ln(z)} - \sigma(z) = \mathcal{O}(h^p) = \mathcal{O}((\ln(z))^p) = \mathcal{O}((z-1)^p).
\]
$3) \Rightarrow 4)$: Setzen wir $z=e^h$ folgt
\[
    \frac{1}{h} \rho(e^h) - \sigma(e^h) = \mathcal{O}(h^p).
\]
Durch Multiplikation mit h erhalten wir
\[
    \mathcal{O}(h^{p+1}) = \rho(e^h) - h \sigma(e^h) = \sum_{j=0}^{k} \alpha_j e^{jh} - h \sum_{j=0}^{k} \beta_j e^{jh}.
\]
Für die Taylor-Entwicklung von der Funktion $e^{jh}$ um $0$ bis zur p-ten Ordnung gilt
\[
    e^{jk} = \sum_{m=0}^{p} \frac{j^m}{m!}h^m + \mathcal{O}(h^{p+1})
    = 1 + \sum_{m=1}^{p} \frac{j^m}{m!}h^m + \mathcal{O}(h^{p+1}).
\]
Einsetzen in die obige Gleichung ergibt
\begin{align*}
    \mathcal{O}(h^{p+1})
    &= \sum_{j=0}^{k} \alpha_j  \left( 1 + \sum_{m=1}^{p} \frac{j^m}{m!}h^m \right)
    - h \sum_{j=0}^{k} \beta_j  \left( 1 + \sum_{m=1}^{p} \frac{j^m}{m!}h^m \right) \\
    &= \sum_{j=0}^{k}\alpha_j + \sum_{m=1}^{p} h^{m} \sum_{j=0}^{k}
    \left( \frac{j^m}{m!} \alpha_j - \frac{j^{m-1}}{(m-1)!}\beta_j \right) + \mathcal{O}(h^{p+1}).
\end{align*}
Wir können die Summationsreihenfolge tauschen, da beide Summen endlich sind. Damit die Gleichung erfüllt ist, muss
gelten:
\[
    \sum_{j=0}^{k} \alpha_j = 0, \qquad
    \sum_{j=0}^{k} \left( \frac{j^m}{m!}\alpha_j - \frac{j^{m-1}}{(m-1)!}\beta_j \right) = 0 \quad
    \text{ für } m = 1, \dots, p.
\]
Somit gilt $4)$.\\
$4) \Rightarrow 1)$: Wir betrachten die Taylor-Entwicklungen
\begin{align*}
    x(t_i + jh) &= \sum_{m=0}^{p} \frac{(jh)^m}{m!}x^{m}(t_i) + x^{(p+1)}(\xi)\frac{(jh)^{p+1}}{(p+1)!}, \quad
    \xi \in [t_i, t_i + jh], \\
    x^{\prime}(t_i + jh) &= \sum_{m=0}^{p-1} \frac{(jh)^m}{m!}x^{m+1}(t_i) + x^{(p+1)}(\eta)\frac{(jh)^{p+1}}{(p+1)!},
    \quad \eta \in [t_i, t_i + jh].
\end{align*}
Für den lokalen Diskretisierungsfehler gilt dann
\begin{align*}
    \tau(t_i,h) &= \frac{1}{h} \sum_{J=0}^{k} \alpha_j x(t_i + jh) - \sum_{j=0}^{k} \beta_j f(t_i+jh,x(t_i+jh))\\
    &= \sum_{j=0}^{k}\left( \frac{1}{h}\alpha_j \left( \sum_{m=0}^{p} \frac{(jh)^m}{m!}x^{\prime}(t_i)  \right)
    - \beta_j \left( \sum_{m=1}^{p} \frac{(jh)^{m-1}}{(m-1)!}x^{\prime}(t_i) \right) \right) + \mathcal{O}(h^p) \\
    &= x(t_i) \frac{1}{h} \sum_{j=0}^{k} \alpha_j + \sum_{m=1}^{p} h^{m-1} x^{(m
    )}(t_i)
    \sum_{j=0}^{k}\left( \frac{j^m}{m!} \alpha_j - \frac{j^{m-1}}{(m-1)!} \beta_j \right) + \mathcal{O}(h^p)\\
    &= \mathcal{O}(h^p),
\end{align*}
wobei $f(t_i+jh,x(t_i+jh)) = x^{\prime}(t_i+jh)$ und im letzten Schritt wurden die Eigenschaften von $4)$ genutzt.\\
Mit $\rho(1) = 0$ und $\rho^{\prime}(1)=\sigma(1)$ gilt
\[
    \sum_{j=0}^{k} \alpha_j = 0 \qquad \text{ und } \qquad \sum_{j=0}^{k} j \alpha_j = \sum_{j=0}^{k} \beta_j
\]
Also ist $4)$ für $m=1=p$ erfüllt und daraus folgt mit $1)$ die Konsistenz (von Ordnung $p=1$). \qedwhite
!!TODO: Komvergenz!!\\
%\subsubsection{Stabilität und Stabilitätsgebiete}
%Trotz höherer Konsistenzordnung bei niedrigeren Rechenaufwand können Mehrschrittverfahren bei einfachen
%Differentialgleichungen sehr schlechte Ergebnisse liefern. Das liegt daran, dass die Konvergenz der Mehrschrittverfahren
%im Gegensatz zu den Einschrittverfahren nicht durch alleinige Konsistenz erfüllt ist. Die Mehrschrittverfahren müssen
%außerdem $stabil$ sein. Dazu definieren  wir zuerst eine sogenannte Differenzengleichung.\\
%\begin{definition}
%    Eine \textit{lineare homogene Differenzengleichung k-ter Ordnung mit konstanten Koeffizienten} ist gegeben durch
%    \begin{equation}
%        \label{differenzengleichung}
%        \alpha_k u_{i+k} + \alpha_{k-1} u_{i+k-1} + \dots + \alpha_0 u_i =0, \qquad i \in \mathbb{N}_0
%    \end{equation}
%    mit $\alpha_0, \dots, \alpha_k \in \mathbb{R}$ und $\alpha_k \neq 0$.\\
%    Ein Polynom $\varrho(z) = \alpha_k z^k$ mit den oben gegebenen Koeffizienten wird \textit{charakteristisches Polynom}
%    von \eqref{differenzengleichung} genannt.\\
%    Man nennt die Differenzengleichung \eqref{differenzengleichung} stabil, wenn alle Lösungen $u$, die
%    \eqref{differenzengleichung} erfüllen, beschränkt sind. Außerden heißt \eqref{differenzengleichung} asymptotisch
%    stabil, wenn $u_i \underset{i \rightarrow \infty}{\rightarrow} 0$.
%\end{definition}
%Nun kann man folgende Aussage beweisen:
%\begin{align*}
%    \eqref{differenzengleichung} \text{ist stabil } \Leftrightarrow \quad &1. \text{ alle Nullstellen } z_j \in
%    \mathbb{C} \text{ von } \varrho(z) \text{ erfüllt die Bedingung } |z_j| \leq 1 \\
%    &2. \text{ alle Nullstellen mit } |z_j| = 1 \text{ sind einfach}.
%\end{align*}
%(Beweisskizze siehe \cite[101]{stykelSkriptZurVorlesung2020})\\
%Weiterhin definieren wir die \textit{Nullstabilität} eines linearen k-Schrittverfahrens.
%\begin{definition}{Wurzelbedingung nach Dahlquist}
%    Gegeben sei ein lineares k-Schrittverfahren \eqref{k-step-linear}. Für alle Nullstellen $z_j \in \mathbb{C}$
%    des ersten charakteristischen Polynoms $\rho(z)$ gilt $|z_j| \leq 1$ und falls $|z_j| = 1$ noch zusätzlich einfaches
%    Vorkommen. Dann nennt man \eqref{k-step-linear} nullstabil.
%\end{definition}
%Unter der Annahme ein nullstabiles k-Schrittverfahren vorliegen zu haben, können wir eine Schranke ähnlich wie die
%Butcherschranken angeben.
%\begin{satz}[Erste Dahlquist-Schranke]
%    \label{erste-dahl}
%    Die maximal erreichbare Konsistenzordnung eines nullstabilen linearen k-Schrittverfahrens erfüllt die Bedingungen
%    \begin{alignat*}{2}
%        p &\leq k+2 \qquad &&\text{falls } \frac{\beta_k}{\alpha_k} > 0 \text{ und } k \text{ gerade ist}, \\
%        p &\leq k+1 \qquad &&\text{falls } \frac{\beta_k}{\alpha_k} > 0 \text{ und } k \text{ ungerate ist}, \\
%        p &\leq k \qquad &&\text{falls } \frac{\beta_k}{\alpha_k} \leq 0. \\
%    \end{alignat*}
%    Eine Konsistenzordnung $p=k+2$ kann nur erreicht werden, wenn alle Nullstellen von $\rho(z)$ auf dem Rand des
%    Einheitskreises liegen, also $z_j \in \partial B_1$.
%\end{satz}
%$Beweis$ \cite[386]{ernsthairergerhardwannerSolvingOrdinaryDifferential}
%Jetzt definieren wir noch die Konvergenzordnung eines linearen k-Schrittverfahrens.
%\begin{definition}
%    Für alle Startwerte gilt $e(t_i,h) = \left\lVert x(t_i)-u_i \right\rVert_2 = \mathcal{O}(h^p)$ für $i=0,\dots,k-1$.
%    Dann ist das lineare k-Schrittverfahren \eqref{k-step-linear} konvergent von der Ordnung, falls für den globalen
%    Diskretisierungsfehler
%    \[
%        \left\lVert x(t_i)-u_i \right\rVert_2 = \mathcal{O}(h^p)
%    \]
%    für $t_i = t_0 + ih \in [t_0,t_0+a]$ gilt.
%\end{definition}
%Mit dieser Definition ist es möglich einen Zusammenhang zwischen Konsistenz, Nullstabilität und Konsvergenz herzustellen.
%\begin{satz}
%    1. \eqref{k-step-linear} ist konvergent $\Rightarrow$
%    \eqref{k-step-linear} ist nullstabil und konstistent.\\
%    2. \eqref{k-step-linear} hat Konistenzordnung $p$ und ist nullstabil
%        $\Rightarrow$ \eqref{k-step-linear} ist konvergent von der Ordnung $p$.
%\end{satz}
%$Beweis$ 1. \cite[392]{ernsthairergerhardwannerSolvingOrdinaryDifferential}\\
%2. \cite[395,396]{ernsthairergerhardwannerSolvingOrdinaryDifferential}\\
%Im Folgenden werden wir eine feste Schrittweite $h > 0$ und ein unendliches Zeitintervall $D=[t_0, \infty]$
%betrachten. Mit dem Testproblem
%\begin{align}
%    x^{\prime} &= \lambda x \nonumber \\
%    x(0) &= 1   \label{testprob}
%\end{align}
%kann eine sinnvolle Stabilitätsfunktion für die gegebenen Verfahren hergeleitet werden
%(für k-Schrittverfahren, siehe \cite[103-105]{stykelSkriptZurVorlesung2020})\\
%\begin{definition}
%    Gegeben sei ein konstistentes und nullstabiles lineares k-Schrittverfahren \eqref{k-step-linear}. Man
%    nennt
%    \begin{align}
%        \Pi(z,h \lambda) = \sum_{l=0}^{k} (\alpha_l - h \lambda \beta_l) z^l = \rho(z) - h \lambda \sigma(z)
%        \label{stab-poly}
%    \end{align}
%    das Stabilitätspolynom von \eqref{k-step-linear}. Dabei sind $\rho(z)$ und $\sigma(z)$ das erste und zweite
%    charakteristische Polynom von \eqref{k-step-linear}.\\
%\end{definition}
%\begin{definition}
%    Das Verfahren \eqref{k-step-linear} heißt absolut stabil für $h\lambda$, falls $|z_j(h\lambda)|<1$ für alle
%    Nullstellen $z_j(h\lambda)$ des Stabilitätspolynoms \eqref{stab-poly}. Dabei nennt man die Menge
%    \[
%        \mathcal{S} := \{ h \lambda \in \mathbb{C} : |z_j(h\lambda) < 1 \text{ für } j = 1, \dots, k \}
%    \]
%    Bereich absoluter Stabilität des Verfahrens \eqref{k-step-linear}.
%\end{definition}
%Falls $\mathcal{S}$ die ganze linke komplexe Halbebene $\mathbb{C}^{-}:= \{ z \in \mathcal{C}: Re(z) < 0 \} $ enthält,
%so heißt das Verfahren \eqref{k-step-linear} \textit{A-stabil}. !! TODO: L-stabil?!! \\
%Für A-stabile lineare k-Schrittverfahen lässt sich eine Erweiterung der ersten Dahlquist-Schranke \eqref{erste-dahl}
%finden.
%\begin{satz}[Zweite Dahlquist-Schranke]
%    Ein A-stabiles lineares k-Schrittverfahren \eqref{k-step-linear} hat die Konsistenzordnung $p \leq 2$.
%\end{satz}
%$Beweis.$ \cite[355-358]{peterdeuflhardfolkmarbornemannNumerischeMathematikGewohnliche}
%Für ein \textit{m-stufiges} explizites Runge-Kutta-Verfahren \eqref{exp-rk-def} kann mit dem Testproblem
%\eqref{testprob} die Stabilitätsfunktion wie folgt hergeleitet werden. Mit $u_0=x(t_0)=1$ gilt für $i=0$ gilt für die
%Stufen $k_{l,1}$
%\begin{align*}
%    k_{1,0} &= \lambda \cdot 1 \\
%    k_{l,0} &= \lambda \left( 1 + \sum_{o = 1}^{l-1} a_{lo} k_{o,0} \right), \quad l = 2, \dots, m \\
%\end{align*}
%Dies kann zu einem quadratischem linearen Gleichungssystem
%\[
%    (I - yA)k = \lambda e
%\]
%umwandeln, wobei $I$ die Einheitsmatrix, $k:= (k_1, \dots, k_m)^{\intercal}$, $e:=(1, \dots, 1)^{\intercal}$
%und $y := h\lambda$ sind. Wurde das LGS eindeutig gelöst, ist $(I-yA)$ invertierbar, also haben wir
%$k = (I-yA)^{-1} \lambda e$. Nun können wir im nächsten Schritt $i=1$ dann die erste Approximation angeben
%\[
%    u_1 = u_0 + h \sum_{l=1}^{m} b_l k_{l,0} = 1 + h b^{\intercal} k = 1 + yb^{\intercal}( I - yA)^{-1}e.
%\]
%Dies ergibt die Stabilitätsfunktion $\Pi(y) = 1 + yb^{\intercal}( I - yA)^{-1}e.$ Da wir ein explizites
%Runge-Kutta-Verfahren betrachten, ist $A$ eine untere Dreiecksmatrix und es kann mit Hilfe von Induktion über $m$ zeigen, dass
%die Stabilitätsfunktion ein Polynom vom Grad $m$ ist. Eine genauere Untersuchung der Stabilitätsfunktion von
%Runge-Kutta-Verfahren ist in \cite{ernsthairergerhardwannerSolvingOrdinaryDifferentiala} in den Kapiteln $\RNum{4}.2$
%und $\RNum{4}.3$ zu finden.

\subsection{Verfahren für steife Differentialgleichungen}
Durch Betrachtung steifer Differentialgleichungen, siehe Definition \ref{steife-dgl}, lässt sich leicht bemerken, dass
die Verwendung allgemeiner Ein- oder Mehrschrittverfahren nicht sinnvoll ist. Wir werden später dazu ein Beispiel in
\ref{sec:steife-differentialgleichung} betrachten. Die resultierenden Vefahren werden
\textit{Rückwärtsdifferenzenverfahren} (oder BDF) genannt. Zur Herleitung eines BDF-Verfahrens interpolieren wir zuerst
die Lösung $x(t)$ von \eqref{first-order-num} durch ein Polynom $p \in \mathbb{R}_k[t]$ mit $p(t_{i+j}) = x(t_{i+j})$ für
$j=0, \dots, k$. Unter Verwendung der Lagrange-Interpolationsformel
\[
    p(t) = \sum_{l=0}^{k} x(t_{i+j}) \mathcal{L}_{i+j}(t) \quad \text{mit} \quad
    \mathcal{L}_{i+j}(t) = \prod\limits_{\underset{l \neq j}{l=0}}^{k} \frac{t-t_{i+l}}{t_{i+j}-t_{i+l}}
\]
erhalten wir die Approximation
\[
    f(t_{i+k},x(t_{i+k})) = x^{\prime}(t_{i+k}) \approx p^{\prime}(t_{i+k})
    = \sum_{l=0}^{k} x(t_{i+j})\mathcal{L}^{\prime}_{i+j}(t_{i+k}).
\]
Durch Ersetzen der unbekannten Werte $x(t_{i+j})$ durch Näherungen $u_{i+j}$ resultiert das BDF-Verfahren
\[
    \sum_{j=0}^{k}\alpha_j u_{i+j} = h f(t_{i+k}, u_{i+k})
\]
mit
\[
    \alpha_j = h \mathcal{L}^{\prime}_{i+j} (t_{i+k}), \quad j=0,\dots,k,
\]
welches ein implizites lineares $k$-Schrittverfahren ist.\\

